behaviors:
  RTSBrain:
    trainer_type: ppo
    hyperparameters:
      batch_size: 2048
      buffer_size: 20480
      learning_rate: 3.0e-4
      beta: 5.0e-3 # Entropy'yi biraz düşürdük ki rastgelelik azalsın
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 512
      num_layers: 2
      vis_encode_type: simple
      memory:
        sequence_length: 64
        memory_size: 256
    reward_signals:
      extrinsic:
        gamma: 0.995
        strength: 1.0

      # --- GAIL (Stil Öğretmeni) ---
      gail:
        gamma: 0.99
        strength: 0.1 # GAIL'i azalttık, BC işi yapacak
        network_settings:
          normalize: true
          hidden_units: 128
          num_layers: 2
          vis_encode_type: simple
        learning_rate: 3.0e-4
        use_actions: false
        use_vail: false
        demo_path: Assets/Demonstrations/RTSDemoHuman01_8.demo

    # --- BURASI ÇOK ÖNEMLİ: BEHAVIORAL CLONING (Taklitçi) ---
    behavioral_cloning:
      strength: 1.0 # Birebir kopyalamaya zorlar
      demo_path: Assets/Demonstrations/RTSDemoHuman01_8.demo
      steps: 50000 # İlk 50k adımda sadece taklit etsin, sonra kendi öğrensin
      batch_size: 2048 # Hiperparametrelerdeki batch_size ile aynı veya yakın olsun

    max_steps: 1000000
    time_horizon: 1024
    summary_freq: 2000
